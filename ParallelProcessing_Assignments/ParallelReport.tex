\documentclass[12pt]{report}

\usepackage[left=30mm,right=15mm,
top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}  
\usepackage[russian]{babel}
\usepackage{textcomp}
\usepackage{graphicx}
\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{caption}
\usepackage{paracol}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{listings}
\hypersetup{
	colorlinks = true, %Colours links instead of ugly boxes
	urlcolor = blue, %Colour for external hyperlinks
	linkcolor = blue, %Colour of internal links
	citecolor = red %Colour of citations
}
\titleformat{\chapter}[display]{\normalfont\Large\bfseries}{\chaptertitlename\ \thechapter}{14pt}{\Large}
\begin{document}
	\begin{titlepage}
		\begin{center}
				Федеральное государственное автономное образовательное учреждение\\
				высшего образования\\
				"Московский физико-технический институт (государственный университет)"\\
				Физтех-школа аэрофизики и космических исследований\\
				Кафедра перспективных технологий для систем безопасности\\
		\end{center}
		\begin{center}
			\vspace{2cm}
			\textbf{ОТЧЕТ ПО КУРСУ\\
			<<ОСНОВЫ ПАРАЛЛЕЛЬНОГО ПРОГРАММИРОВАНИЯ>>}\\
			\vspace{5cm}
		\end{center}
			\begin{paracol}{2}
				\switchcolumn
				\textbf{Студент:}\\
				Макаров Николай Романович\\
				\textbf{Преподаватель:}\\
				Акимов Владимир Владимирович,\\
			\end{paracol}
		\begin{center}
			\vspace{6cm}
			\textbf{г. Долгопрудный\\
				2019}
		\end{center}
	\end{titlepage}


\tableofcontents
%\setcounter{tocdepth}{2}
%\setcounter{secnumdepth}{2}

\chapter*{Введение}
\addcontentsline{toc}{chapter}{Введение}
\par Парадигма параллельного программирования возникла в 50-х годах 20-го века, практически одновременно с появлением первых ЭВМ. Существующие на тот момент компьютеры не могли дать необходимую скорость вычислений, что привело к возникновению идей о разбиении программ на выполняющиеся одновременно части для ускорения вычислений. На данный момент существуют различные способы ускорения вычислений за счет распараллеливания программ: разделение на несколько потоков/процессов, массивно-параллельные вычисления, MPI. 
\par Данный отчет охватывает два метода параллельного программирования: работа программ в несколько потоков и программы с использованием MPI. Многопоточная программа имеет свои особенности, которые обусловлены спецификой языка программирования Python, на котором и выполнены программы. Так как Python является скриптовым языком и изначально рассчитывался только для работы в одном потоке из соображений потокобезопасности, а также ввиду концепта деления одного пространства имён между всеми имеющимися потоками, реализация многопоточных программ в Python выполнена при помощи Global Interpreter Lock (GIL).
\par GIL отвечает за синхронизацию и очерёдность доступа программы в случае конфликтов имеющихся потоков при попытке получения двумя и более из них доступа к конкретному участку памяти. В данной работе была поставлена задача сравнить идеальную модель распараллеливания программы с реальной ситуацией.
\par Реализация программы с использованием MPI также имеет свои особенности. В отличии от многопоточных программ, реализацию которых поддерживает непосредственно Python, MPI интерфейс реализован в качестве нескольких сторонних библиотек. В данной работе используется библиотека mpi4py, реализующая все основные методы MPI.

\chapter*{Описание программ}
\addcontentsline{toc}{chapter}{Описание программ}
\par Для многопоточной реализации было решено использовать утилиту из системной библиотеки Python, функцию sleep из модуля time. На вход данная функция принимает число - количество секунд, после чего имплементирует простой процессора заданное время. В процессе разработки такие функции зачастую используются для грубой кодировки синхронизации модулей "вручную", например, когда родительскому процессу необходимо подождать инициализации дочернего, или при необходимости отказа в доступе к функционалу на заданное время. Для нас данная функция представляет интерес, так как ввиду её простоты она должна хорошо распараллеливаться и представлять собой идеальный случай
\par При помощи MPI интерфейса реализовано вычисление нормы вектора заданного типа, по умолчанию - L2. На начальном этапе программы генерируется случайный вектор заданного размера, после чего создается указанное при запуске программы количество нод. Каждой ноде пересылается часть вектора, после чего все ноды обмениваются полученными результатами и каждая из них получает полный квадрат нормы вектора (для этого используется операция allreduce).

\chapter*{Архитектура}
\addcontentsline{toc}{chapter}{Архитектура}
\par Вычисления производились на ноутбуке на процессоре Intel Core i5-7200U 64-bit, размер L1 кеша 128kib, l2 - 512kib, а l3 - 3mib на ОС Ubuntu 16.04.1 LTS. Объём оперативной памяти на ноутбуке составляет 4 Gb, но упереться в её объём наше исследование не должно.

\chapter*{Результаты}
\addcontentsline{toc}{chapter}{Результаты}
\par Для анализа был произведён замер времени выполнения описанных выше программ при разном количестве потоков/нод MPI с одинаковыми начальными условиями. Результаты представлены на графиках ниже.
\begin{figure}[h!]
	\centering
	\captionsetup{justification=centering}
	\includegraphics[scale=1]{pic2.png}
	\caption{Время выполнения многопоточной программы от количества потоков}
	\label{fig:Graph 1}
\end{figure}
\par Как и ожидалось, многопоточноя программа показывает линейную зависимость с небольшим отклонением в районе 8 потоков, которое обусловлено растущими затратами процессорного времени на создание и управление потоками.
\begin{figure}[h!]
	\centering
	\captionsetup{justification=centering}
	\includegraphics[scale=1]{pic1.png}
	\caption{Время выполнения программы с использованием MPI от количества нод}
	\label{fig:Graph 2}
\end{figure}
\par В случае программы с MPI ассимптотика начинает наблюдаться гораздо более явно и "раньше" относительно числа потоков, нежели чем при исполнении многопоточной программы. Это обусловлено более сложной структурой концепта MPI, а также временными затратами на инициализацию нод и затратами на коммуникацию нод, в многопоточном случае которыми можно пренебречь. Также на данном этапе начинает сказываться относительно небольшой для данного процессора размер L1 - кеша.


\chapter*{Заключение}
\addcontentsline{toc}{chapter}{Заключение}
\par В результате проделанной работы изучены возможности языка Python для параллельного программирования, а также проверен на практике закон Амдаля. Также освоены базовые понятия и операции, используемые для MPI интерфейсов.



\end{document}
